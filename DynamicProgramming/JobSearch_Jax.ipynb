{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jax to increase computation speed\n",
    "\n",
    "[Jax](https://jax.readthedocs.io/en/latest/quickstart.html) is a library focus on high performance computing by offering an simple API with a Numpy-like interface that offers the following features:\n",
    "- Computations on CPU, GPU, and TPU\n",
    "- Just-In-Time compilation (JIT)\n",
    "- Automatic differentiation (autograd)\n",
    "\n",
    "Below, we illustrate how Jax can be applied to a dynamic programming problem, specifically the McCall job search model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline Solution to the McCall model\n",
    "\n",
    "We begin with our baseline solution to the McCall model, found by iterating on the value function and using Numpy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bellman operator\n",
    "def Tv(V, b, beta, p, wages):\n",
    "    EV = np.sum(V * p)\n",
    "    v_search = b + beta * EV\n",
    "    v_accept = wages / (1 - beta)\n",
    "    TV = np.maximum(v_accept, v_search)\n",
    "    return TV\n",
    "\n",
    "# Define function to solve the job search problem\n",
    "def McCall_VFI(theta=0.3, beta=0.99, mu=40, sigma=0.5, w_min=10, w_max=100, n=1_000_000, v_tol=1e-6, max_iter=1000):\n",
    "    # default distribution wages\n",
    "    wages = np.linspace(w_min, w_max, n+1)\n",
    "    # vector of probabilities of each wage being drawn from log normal distribution\n",
    "    p = stats.lognorm.pdf(wages, s=sigma, scale=mu)\n",
    "    p = p / p.sum() # normalize for truncated distribution\n",
    "    # set other model parameters\n",
    "    expected_wage = np.sum(wages * p)\n",
    "    b = theta * expected_wage  # b is replacement rate, c is unemployment benefit\n",
    "    V = np.zeros(wages.size)  # value function guess, could have better one\n",
    "    phi = np.zeros(wages.size) # policy function\n",
    "    v_dist = 10\n",
    "    iter = 0\n",
    "    while (v_dist > v_tol) & (iter < max_iter):\n",
    "        TV = Tv(V, b, beta, p, wages)\n",
    "        v_dist = np.abs(V-TV).max()\n",
    "        V = TV\n",
    "        iter += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 546 ms, sys: 698 ms, total: 1.24 s\n",
      "Wall time: 1.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7643.33969033,  7643.33969033,  7643.33969033, ...,\n",
       "        9999.982     ,  9999.991     , 10000.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time McCall_VFI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on if we have a GPU available\n",
    "\n",
    "NOTE: I don't know to do this on Windows generally.  If trying from the command line, you can use `nvidia-smi.exe` to check if you have a GPU available, but I think you need to be in the directory where your GPU drivers are installed (see [this Stack Overflow](https://stackoverflow.com/questions/57100015/how-do-i-run-nvidia-smi-on-windows)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics/Displays:\n",
      "\n",
      "    Apple M1 Max:\n",
      "\n",
      "      Chipset Model: Apple M1 Max\n",
      "      Type: GPU\n",
      "      Bus: Built-In\n",
      "      Total Number of Cores: 32\n",
      "      Vendor: Apple (0x106b)\n",
      "      Metal Support: Metal 3\n",
      "      Displays:\n",
      "        Color LCD:\n",
      "          Display Type: Built-in Liquid Retina XDR Display\n",
      "          Resolution: 3024 x 1964 Retina\n",
      "          Main Display: Yes\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Automatically Adjust Brightness: Yes\n",
      "          Connection Type: Internal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "# !nvidia-smi  # linux\n",
    "!system_profiler SPDisplaysDataType # mac silicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solution with Jax\n",
    "\n",
    "Now we solve the same model, but replace our `np.` calls with `jnp.` calls. We also use the `device_put` function to move our arrays to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bellman operator with Jax functions\n",
    "def Tv_jax(V, b, beta, p, wages):\n",
    "    EV = jnp.sum(V * p)\n",
    "    v_search = b + beta * EV\n",
    "    v_accept = wages / (1 - beta)\n",
    "    TV = jnp.maximum(v_accept, v_search)\n",
    "    return TV\n",
    "\n",
    "\n",
    "# Define function to solve the job search problem\n",
    "def McCall_VFI_jax(theta=0.3, beta=0.99, mu=40, sigma=0.5, w_min=10, w_max=100, n=1_000_000, v_tol=1e-6, max_iter=1000):\n",
    "    # default distribution wages\n",
    "    wages = np.linspace(w_min, w_max, n+1)\n",
    "    # vector of probabilities of each wage being drawn from log normal distribution\n",
    "    p = stats.lognorm.pdf(wages, s=sigma, scale=mu)\n",
    "    p = p / p.sum() # normalize for truncated distribution\n",
    "    # set other model parameters\n",
    "    expected_wage = np.sum(wages * p)\n",
    "    b = theta * expected_wage  # b is replacement rate, c is unemployment benefit\n",
    "    V = np.zeros(wages.size)  # value function guess, could have better one\n",
    "    phi = np.zeros(wages.size) # policy function\n",
    "\n",
    "    # Shift all NumPy arrays onto the GPU\n",
    "    wages = jax.device_put(wages)\n",
    "    p = jax.device_put(p)\n",
    "    V = jax.device_put(V)\n",
    "    phi = jax.device_put(phi)\n",
    "\n",
    "    v_dist = 10\n",
    "    iter = 0\n",
    "    while (v_dist > v_tol) & (iter < max_iter):\n",
    "        TV = Tv_jax(V, b, beta, p, wages)\n",
    "        v_dist = jnp.abs(V-TV).max()\n",
    "        V = TV\n",
    "        iter += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 775 ms, sys: 449 ms, total: 1.22 s\n",
      "Wall time: 653 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([ 7643.3257,  7643.3257,  7643.3257, ...,  9999.981 ,  9999.991 ,\n",
       "       10000.    ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time McCall_VFI_jax().block_until_ready()  # using block_until_ready to get accurate timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Jax **reduces the time to solve the model by about 2/3**.\n",
    "\n",
    "## 3. Solution with Jax GPU + JIT\n",
    "\n",
    "Finally, we use the `jit` function to compile our function and run it on the GPU. This further reduces the time to solve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Jitting\" the Bellman operator\n",
    "Tv_jax_jit = jax.jit(Tv_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336 ms ± 9.35 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "74.4 ms ± 2.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "40.5 ms ± 609 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "theta=0.3\n",
    "beta=0.99\n",
    "mu=40\n",
    "sigma=0.5\n",
    "w_min=10\n",
    "w_max=100\n",
    "n=100_000_000\n",
    "wages = np.linspace(w_min, w_max, n+1)\n",
    "p = stats.lognorm.pdf(wages, s=sigma, scale=mu)\n",
    "p = p / p.sum() # normalize for truncated distribution\n",
    "mean_wage = np.sum(wages * p)\n",
    "b = theta * mean_wage\n",
    "V = np.zeros(wages.size)\n",
    "\n",
    "## FOR Jax calls, put the arrays on the GPU\n",
    " # Shift all NumPy arrays onto the GPU\n",
    "beta_j = jax.device_put(beta)\n",
    "b_j = jax.device_put(b)\n",
    "wages_j = jax.device_put(wages)\n",
    "p_j = jax.device_put(p)\n",
    "V_j = jax.device_put(V)\n",
    "\n",
    "%timeit Tv(V, b, beta, p, wages)\n",
    "%timeit Tv_jax(V_j, b_j, beta_j, p_j, wages_j).block_until_ready()\n",
    "%timeit Tv_jax_jit(V_j, b_j, beta_j, p_j, wages_j).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usitc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
